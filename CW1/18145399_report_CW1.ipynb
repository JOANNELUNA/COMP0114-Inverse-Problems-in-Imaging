{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP0114 Inverse Problems in Imaging Coursework 1\n",
    "##### Student ID 18145399\n",
    "## 1. Solving Underdetermined Problems\n",
    "a) Define a function ```phi(x2,p)``` of two variables, $x_2$ and $p$, to compute the value of $\\Phi$ as given below.\n",
    "$$\\Phi = \\sum_{i}{|x_i|^p}$$ \n",
    "i.e. $\\Phi = |x_1|^p + |x_2|^p$\n",
    "where $x_i$ satisfies $x_1+2x_2=5$.\n",
    "The reason I used $x_2$ to be an input instead of $(x_1,x_2)$ is that optimization function I used in b) need parameter to be 1D-array.\n",
    "\n",
    "```python\n",
    "def phi(x2,p):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        x2 is one element of a vector of length 2 (x1,x2)\n",
    "        p is a scalar\n",
    "    Returns:\n",
    "        phi    \n",
    "    \"\"\"\n",
    "    # x1 = 5-2*x2\n",
    "    Sum = (np.abs(5-2*x2))**p + (np.abs(x2))**p\n",
    "    \n",
    "    return Sum\n",
    "    ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Use library function ```scipy.optimize.minimize(phi,x_start,args=p_i)``` to solve the constrained optimization problem\n",
    "$$\\text{minimize} \\quad \\Phi = \\sum_{i}{|x_i|^p}$$ \n",
    "for $p$ in range of $(1, 1.5, 2, 2.5,3,3.5,4)$.\n",
    "\n",
    "The input phi is the function need to be optimised, x_start is a start point of $x_2$ to find the solution, args is the constant parameter in the optimising function and the result of this function has the structure of:\n",
    "```\n",
    "fun: 2.500000011175871\n",
    "hess_inv: array([[1.73444551]])\n",
    "    jac: array([0.])\n",
    "message: 'Optimization terminated successfully.'\n",
    "    nfev: 104\n",
    "    nit: 3\n",
    "    njev: 52\n",
    "status: 0\n",
    "success: True\n",
    "    x: array([2.49999999])\n",
    "```\n",
    "\n",
    "To plot the solution, we only need the ```x = reuslt.x``` and ```y = result.fun``` when ```result.success == True```. And I got the solution point:\n",
    "```\n",
    "when p = 1.5: \n",
    "x=([0.5555566042412448, 2.2222216978793776]), y = 3.726779962500272 \n",
    "when p = 2.0: \n",
    "x=([0.9999995008103717, 2.000000249594814]), y = 5.000000000000312 \n",
    "when p = 2.5: \n",
    "x=([1.1976615735037677, 1.9011692132481162]), y = 6.553467806802202 \n",
    "when p = 3.0: \n",
    "x=([1.3060193930427793, 1.8469903034786104]), y = 8.528433037009236 \n",
    "when p = 3.5: \n",
    "x=([1.3739978884128101, 1.813001055793595]), y = 11.064585668127403 \n",
    "when p = 4.0: \n",
    "x=([1.4205182909810472, 1.7897408545094764]), y = 14.33212122809243\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C) The plot of solution points on the constraint line $x_1+2x_2=5$ is shown below.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![solution](output.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Another way to find the solution is using the Moore-Penrose generalised inverse\n",
    "$A^\\dagger:=A^\\intercal(AA^\\intercal)^{-1}$ and applying it to get solution $x_{MP} =A^\\dagger b $. As shown below, the solution I got by using this method is same as the solution obtaining with previous method when $p = 2$. The reason of similarity is that Moore–Penrose pseudoinverse is commonly used to compute a least squares solution to a system of linear equations that lacks a unique solution, which is asked the degree of equation to be 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![solution](1d.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Singular Value Decomposition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Firstly, define a function ```grid(n)``` to set up a equally spaced grid on the interval [−1,1] with library function ```np.linspace(-1,1,n)``` where n is the number of steps. \n",
    "```python\n",
    "def grid(n):\n",
    "    g = np.linspace(-1,1,n)\n",
    "    return g\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Then define a Gaussian function centred at $µ = 0$ with $σ = 0.2$ by equation\n",
    "$$G(x) = \\frac{δn}{\\sqrt{2π}σ}exp(−\\frac{(x−µ)^2}{2σ^2})$$ \n",
    "```python\n",
    "def Gaussian(X,sigma,miu):\n",
    "    G = []\n",
    "    for x in X:\n",
    "        dn = 2/(len(X)-1)\n",
    "        G.append((dn/(np.sqrt(2*np.pi)*sigma)) * np.exp(-((x-miu)**2)/(2*sigma**2)))\n",
    "    return G\n",
    "```\n",
    "\n",
    "\n",
    "and evaluate it along the grid set in part a). The result of evaluation is shown below as a plot.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![solution](2b.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Then define a convolution matrix $A$ based on Gaussian of size $n × n$ with entires\n",
    "$$A_{i,j} = G(x_i −x_j) = \\frac{δn}{\\sqrt{2π}σ}exp(−\\frac{(x_i−x_j)^2}{2σ^2})$$\n",
    "\n",
    "```python\n",
    "def Convolution_Matrix(n,sigma):\n",
    "    M = np.zeros((n,n))\n",
    "    # step size dn\n",
    "    dn = 2/(n-1)\n",
    "    X = grid(n)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            M[i,j] = ((dn/(np.sqrt(2*np.pi)*sigma)) * np.exp(-((X[i]-X[j])**2)/(2*sigma**2)))\n",
    "    return M\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) The convolution matrix with size $n = 100$ can be visualised by rescaling the matrix and explicitly defining a colormap with the codes \n",
    "```python\n",
    "import cv2 \n",
    "import numpy as np \n",
    "A = Convolution_Matrix(100,sigma)\n",
    "# rescaling matrix A\n",
    "Atmp = np.array(np.ceil(A/np.max(A)*256), dtype = np.uint8) \n",
    "# plot rescaled matrix A\n",
    "Aimg = cv2.applyColorMap(Atmp, cv2.COLORMAP_JET) \n",
    "cv2.imwrite(\"2d.png\",Aimg)\n",
    "``` \n",
    "This graph satisfies my expectation as matrix A is diagonally symmetric resulted from its calculation equation of entries."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![solution](2d.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Now, let's compute SVD of convolution matrix by library function ```U,W,V_T = np.linalg.svd(A)``` in which ```V_T``` is the transpose of matrix $V$ and $W$ is the entries'list of diagonal matrix containing the singular values with size $n$. And the results ```U```,```W``` and ```V_T``` is satisfied the equation $A = UWV^T$ within a tolerance: $2.434181540759949 ×10^{-15}$, where the tolerance is the norm of two product calculated by ```np.linalg.norm(A - (U * W) @ V_T)```."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Now, compute the pseudoinverse $A^†$ of $A$.\n",
    "\n",
    "i) Firstly, constructe $W^†$ into a sparse matrix by using two scipy functions\n",
    "```python\n",
    "Wdiag = scipy.sparse.spdiags(W,0,A.shape[0],A.shape[1])\n",
    "W_inv = scipy.sparse.linalg.inv(Wdiag) \n",
    "```\n",
    "\n",
    "\n",
    "ii) Then For the case $n = 10$, check if $WW^† = W^†W = n×n$ Identity matrix by\n",
    "```python\n",
    "# set a n*n identity matrix\n",
    "identity_n = np.identity(N)\n",
    "# check if WW^† = W^†W\n",
    "if (Wdiag.todense() * W_inv).all() == (W_inv.todense() * Wdiag).all():\n",
    "    print('Two products about W are the same.')\n",
    "else: \n",
    "    print('Two products about W are not the same.')\n",
    "#check if WW^† = n*n identity matrix\n",
    "if ((Wdiag.todense() * W_inv).all() == (identity_n).all()):\n",
    "    print('Two products about W are identity.')\n",
    "```\n",
    "with the outputs\n",
    "```\n",
    "Two products about W are the same.\n",
    "Two products about W are identity.\n",
    "```\n",
    "\n",
    "\n",
    "iii) Then, compute the pseudoinverse $A^†$ of $A$ by using both the library function ```np.linalg.pinv(A)``` and the formula $A^† = VW^†U^T$. \n",
    "```python\n",
    "# use library function\n",
    "A_inv = np.linalg.pinv(A)\n",
    "# use formula\n",
    "A_pinv = V_T.T @ W_inv @ U.T\n",
    "```\n",
    "\n",
    "\n",
    "vi) Check also that $AA^† = A^†A = Id_n$ for $n = 10$ by codes:\n",
    "```python\n",
    "# norm of difference between A†A and AA†\n",
    "norm = (np.linalg.norm(A * A_inv - A_inv * A))\n",
    "# norm of difference between pseudoinverse A† calculated by twio methods\n",
    "norm_Apinv = np.linalg.norm(A_inv - A_pinv)\n",
    "# check two A†\n",
    "if np.allclose(A_inv, A_pinv):\n",
    "    print('Two A† is element-wise equal within a tolerance:',norm_Apinv)\n",
    "else:\n",
    "    print('Two A† is not equal with a norm:',norm_Apinv)\n",
    "# check two products\n",
    "if np.allclose(A * A_inv, A_inv * A):\n",
    "    print('Two products about A are element-wise equal within a tolerance:',norm)\n",
    "else:\n",
    "    print('Two products about A are not equal with a norm:',norm)\n",
    "# check if products are identity\n",
    "product = (A * A_inv)\n",
    "product[product < 2*1e-15] = 0 \n",
    "if (product.all() == identity_n.all()):\n",
    "    print('Two products about A are identity.')\n",
    "``` \n",
    "with the outputs\n",
    "```\n",
    "Two A† is element-wise equal within a tolerance: 2.8400347913994436e-15\n",
    "Two products about A are element-wise equal within a tolerance: 0.0\n",
    "Two products about A are identity.\n",
    "```\n",
    "\n",
    "![solution](2f_n10.png)\n",
    "\n",
    "#### Brief discussion\n",
    "The overall result is:\n",
    "```\n",
    "When the size of marix is 10 :\n",
    "Two products about W are the same.\n",
    "Two products about W are identity.\n",
    "Two A† is element-wise equal within a tolerance: 2.8400347913994436e-15\n",
    "Two products about A are element-wise equal within a tolerance: 0.0\n",
    "Two products about A are identity.\n",
    "```\n",
    "Among the five equivalence eqaution for $n =10$, only ```np.linalg.pinv(A) == V_T.T @ W_inv @ U.T``` exists inequivalence which might be resulted from the computing memeory shortage as the size of matrix product."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Repeat e) and f) for n = 20, obtain:\n",
    "```\n",
    "When the size of marix is 20 :\n",
    "Two products about W are the same.\n",
    "Two products about W are identity.\n",
    "Two A† is element-wise equal within a tolerance: 3.7416236697031865e-10\n",
    "Two products about A are element-wise equal within a tolerance: 0.0\n",
    "Two products about A are identity.\n",
    "```\n",
    "![solution](2g_n20.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, choose $n = 100$.\n",
    "\n",
    "In this case, there is a difference against previous two:\n",
    "```\n",
    "When the size of marix is 100 :\n",
    "Two products about W are the same.\n",
    "Two products about W are identity.\n",
    "Two A† is not equal with a norm: 1.4308362856453842e+17\n",
    "Two products about A are element-wise equal within a tolerance: 0.0\n",
    "Two products about A are identity.\n",
    "```\n",
    "![solution](2g_n100_W+.png)\n",
    "\n",
    "The difference between two A† is extermely large. Also, when n > 30, two A† is hardly equal with norms larger than 0.031135550123037235.\n",
    "\n",
    "Now, plot the first 9 columns of $V$, the last 9 columns of $V$, and the singular diagonal $W$ on a log-scale, i.e. log(diag($W$))\n",
    "\n",
    "![solution](2g_n100_V1.png)\n",
    "![solution](2g_n100_V2.png)\n",
    "![solution](2g_n100_W.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brief discussion\n",
    "The 5 equivalence equations still performance similarly as when $n = 10$, but there is a larger difference betwen two $A^†$, with a value that is still in the acceptable error range. However when $n = 100$, the difference betwen two $A^†$ far exceeds the tolerance threshold with an extremly high value of $1.4308362856453842 × 10^{17}$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convolutions and Fourier transform\n",
    "a) Create a step function $f(x)$ defined by\n",
    "$$f(x) = χ_{(−0.95,−0.6]}(x) + 0.2χ_{(−0.6,−0.2]}(x) − 0.5χ_{(−0.2,0.2]}(x) + 0.7χ_{(0.4,0.6]}(x) − 0.7χ_{(0.6,1]}(x)$$\n",
    "where $χ(x)$ of an interval (a,b] is defined by\n",
    "$$ χ(x) =\n",
    "  \\begin{cases}\n",
    "    1       & \\quad \\text{for } a <x≤b \\\\\n",
    "    0       & \\quad \\text{otherwise } \n",
    "  \\end{cases}.\n",
    "$$\n",
    "```python\n",
    "def f(x):\n",
    "    chi1 = lambda x : 1 if -0.95 < x <= -0.6 else 0;\n",
    "    chi2 = lambda x : 1 if -0.6 < x <= -0.2 else 0;\n",
    "    chi3 = lambda x : 1 if -0.2 < x <= 0.2 else 0;\n",
    "    chi4 = lambda x : 1 if 0.4 < x <= 0.6 else 0;\n",
    "    chi5 = lambda x : 1 if 0.6 < x <= 1 else 0;\n",
    "    result = chi1(x) + 0.2*chi2(x) - 0.5*chi3(x) + 0.7*chi4(x) - 0.7*chi5(x)\n",
    "    return result\n",
    "```\n",
    "\n",
    "And plot it on a grid on the interval [−1,1] with a step number $n = 500% to make jump line completely vertical ($n = 200$ with step size $dn = 0.01$ is enough for resolve the jump).\n",
    "\n",
    "![solution](3a1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Then obtain matrix A with function ```Convolution_Matrix(n,sigma)``` for σ = 0.05, 0.1, 0.2 and plot the singular values $W$ from \n",
    "```python\n",
    "A = Convolution_Matrix(n,sigma)\n",
    "U,W,V_T = np.linalg.svd(A)\n",
    "```\n",
    "![solu](3b.png)\n",
    "![solu](3b2.png)\n",
    "![solu](3b3.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Shown from above graphs, the singular values is following a Gaussian function. To determine the variance of this Gaussian, use ```popt, pcov = scipy.optimize.curve_fit(half_Gaussian,x,W)``` where \n",
    "* ```popt``` is the best-fit optimising parameter, \n",
    "* ```half_Gaussian``` is the function with input of ```(x>0, sigma)``` and returns the Gaussian value on the x>0 interval.\n",
    "* ```x``` is the grid of singular values W.\n",
    "* and ```W``` is the singular values shown on the graph which I want to fit the Gasussian in.\n",
    "\n",
    "Firstly define the function by\n",
    "```python\n",
    "def half_Gaussian(x,sigma):\n",
    "    x_all = np.append((-x[::-1]),x[1:])\n",
    "    G = Gaussian(x_all,sigma,0)\n",
    "    x_size = int((len(x_all)+1)/2)\n",
    "    return G[-x_size:]\n",
    "```\n",
    "\n",
    "Then apply the ```scipy.optimize.curve_fit``` to find the best fit Gaussians, and get the varaince of them as:\n",
    "```\n",
    "When sigma = 0.05, the variance of Gaussian is [6.66570836e-05].\n",
    "When sigma = 0.1, the variance of Gaussian is [6.77037328e-05].\n",
    "When sigma = 0.2, the variance of Gaussian is [7.15376509e-05].\n",
    "```\n",
    "**Which is not as expected (there might be some wrong when using the ```curve_fit```.)**\n",
    "\n",
    "And the graphs of the singular values and Gaussian values are shown below:\n",
    "\n",
    "\n",
    "![sol](3c.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Using matrix multiplication obtain the convolution of the step functin f(x) for three choices of σ and plot them as below.\n",
    "\n",
    "![sol](3d.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3cd552944392a340e4d87208eb147b66f5737c7c49723a5c9714d75ec793160"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
