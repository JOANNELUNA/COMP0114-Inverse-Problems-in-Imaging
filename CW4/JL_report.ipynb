{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOMP0114 Inverse Problems in Imaging. Coursework 4\n",
    "## Part A \n",
    "### 1. Calculate the Radon transform of an image and test the back-projection method.\n",
    "(1) Firstly, I load and display the Shepp-Logan phantom image of size 128 ×128 with a numpy file called 'SLphan.npy', which is a commonly used test image in medical imaging. The Shepp-Logan phantom is a 2D image that simulates the attenuation properties of various tissue types in a human head, and is often used to test and evaluate image reconstruction algorithms. I refer this 128 ×128 image as $f_{true}$.\n",
    "\n",
    "![solution](ftrue.png)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Then, I generate the sinogram of the Shepp-Logan phantom image using the ASTRA toolbox, which is a collection of fast and accurate algorithms for tomographic image reconstruction, with following steps:\n",
    "\n",
    "* Firstly, create a *volume geometry object* using the function `create_vol_geom` and the dimensions of the original image. This object specifies the size and shape of the 2D volume that the image will be reconstructed into.\n",
    "\n",
    "* Secondly, generates a set of *projection geometries* using the `create_proj_geom` function from `ASTRA`. These geometries specify the angles at which projections of the image will be taken, as well as the number of detector pixels in each projection.\n",
    "\n",
    "* Thirdly, create a *projector object* using the `create_projector` function from `ASTRA`. This object is used to project the image onto the detector array, which generates the sinogram.\n",
    "\n",
    "* Then, generate the *sinogram* of the Shepp-Logan phantom image using the `create_sino` function from `ASTRA`. This function takes the *original image data* and *projector object* as input, and returns the sinogram data as output.\n",
    "\n",
    "![solution](signogram.png)\n",
    "\n",
    "**For the size of this sinogram and how is this determined:**\n",
    "\n",
    "* The size of the sinogram is determined by the number of projection angles and the number of projection positions for each angle (which is the same as the length of the diagonal of the image, rounded up to the nearest integer). In this case, since the Shepp-Logan phantom has a size of $(128, 128)$, the length of the diagonal is $\\sqrt{128^2 + 128^2} \\approx 181$, so the sinogram has a size of $(180, 181)$. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Then, I perform a simple unfiltered back-projection reconstruction of the Shepp-Logan phantom image using the ASTRA toolbox. with following steps:\n",
    "\n",
    "* Firstly, creates a *data object for the reconstruction* using the `data2d.create` function from `ASTRA`. This object specifies the size and shape of the 2D volume that the image will be reconstructed into.\n",
    "\n",
    "* Secondly, set up the parameters for the back-projection reconstruction using the `astra_dict` function from `ASTRA`. These parameters include the *data and geometry objects for the reconstruction and sinogram*, as well as the *projector object* used to generate the sinogram.\n",
    "\n",
    "* Thirdly, create an *algorithm object* from the configuration structure using the `algorithm.create` function from `ASTRA`. This object specifies the reconstruction algorithm to be used, which in this case is the unfiltered back-projection algorithm ('BP').\n",
    "\n",
    "* Finally, executes the back-projection algorithm using the `algorithm.run` function from `ASTRA`, and return reconstructed image data by using `data2d.get` function.\n",
    "\n",
    "![solution](BP.png)\n",
    "\n",
    "For the size of the back-projected image:\n",
    "\n",
    "* The size of BP image is $(128, 128)$ which is the same as the size of origianl image.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Then, I use the ASTRA toolbox to perform a filtered back-projection reconstruction of the Shepp-Logan phantom image. \n",
    "\n",
    "* The reconstruction steps were similar to those used for unfiltered back-projection reconstruction, with the alternative step of creating an algorithm object that specifies the reconstruction algorithm as filtered back-projection ('FBP').\n",
    "\n",
    "![solution](FBP.png)\n",
    "\n",
    "**Define whether FBP provide a good estimate of the inverse of the Radon transform:**\n",
    "\n",
    "By computing the mean squared error (MSE) and peak signal-to-noise ratio (PSNR) for the unfiltered back-projection and filtered back-projection reconstructed images, compared to the original Shepp-Logan phantom image:\n",
    "\n",
    "Unfiltered back-projection: $MSE = 8670550.3647, PSNR = -69.3805 \\text{dB}$\n",
    "\n",
    "Filtered back-projection: $MSE = 0.01 , PSNR = 20.88 \\text{dB}$\n",
    "\n",
    "MSE stands for Mean Squared Error. It provides a quantitative measure of how much the reconstructed image deviates from the true image. PSNR stands for Peak Signal-to-Noise Ratio. It provides a more human-interpretable measure of image quality, where a higher PSNR value indicates a higher quality image.\n",
    "\n",
    "Overall, the filtered back-projection appears to be a good estimate of the inverse of the Radon transform, as evidenced by the low MSE and high PSNR values. \n",
    "\n",
    "**problems encountered and how they be solved:**\n",
    "\n",
    "* The `add_noise_to_sino` function calculates noise by division with respect to intensity and multiplication with respect to the logarithm of the sinogram. Therefore, it is important to choose a non-zero intensity value and ensure that all components in the sinogram are also non-zero, as division or taking the logarithm of zero is undefined."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) To check how the error in the reconstruction grows with the scale of the measurement noise, I compute the MSE value against the background intensity.\n",
    "\n",
    "![solution](FBP_noise.png)\n",
    "\n",
    "The MSE value is plotted against the background intensity, which is inversely proportional to the noise level, as shown above. \n",
    "\n",
    "The error in reconstruction generally increases as the measurement noise level increases. This is because the noise adds a random component to the measurements, which in turn affects the reconstructed image. The higher the noise level, the more significant the impact on the reconstructed image. Therefore, in general, it is desirable to minimize the measurement noise level to obtain more accurate reconstructions.\n",
    "\n",
    "However, it is important to note that this relationship between background intensity and the error in reconstruction is not linear. The rate of decrease slows down as the background intensity increases. For example, the decrease in error is more significant for background intensity values between 1 and 10 compared to values between 10 and 20, and similarly for values between 10 and 20 compared to values between 20 and 30, and so on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculate an explicit matrix form of the Radon transform and investigate its SVD.\n",
    "\n",
    "The singular value decomposition (SVD) of the explicit matrix form of the Radon transform provides insights into image's properties and structure. In the case of the Radon transform. When varying the range of angles and number of projections, the amount of information available to reconstruct the image is essentially changed. The number of projections determines the amount of information about the object's geometry, while the range of angles determines the coverage of projections. As the number of projections or the range of angles is increased, more information about the object's structure is captured, resulting in a larger number of singular values in the SVD spectrum. \n",
    "\n",
    "(1) Firstly, compute and plot the singular value spectrum for the Radon transform matrix of a given image size $(64, 64)$ and given range of angles as $0-179$ degrees, for *different numbers of projection angles*. \n",
    "\n",
    "The function takes in two arguments: *image_size*, which is an integer specifying the size of the square image to use, and *num_angles_list*, which is a list of integers specifying the number of projection angles to use for each computation.\n",
    "\n",
    "It first creates a zero matrix $A$ of appropriate size, and loops over each pixel in the image. For each pixel, it creates a new image with a single pixel of value $1$ at that position, takes the Radon transform of that image, and reshapes the result into a column vector. The column vector is then added to the matrix $A$.\n",
    "\n",
    "Once all the columns have been added to $A$, the function computes the singular value decomposition of $A$ using NumPy's `linalg.svd` function. It then plots the singular values of the matrix against their index, both for each individual computation and for all the computations together.\n",
    "\n",
    "![solution](SVD_n_all.png)\n",
    "\n",
    "![solution](SVD_n.png)\n",
    "\n",
    "The graph above shows the distribution of singular values of the Radon transform matrix for different numbers of projections (i.e. angles) in the range 0 to 180 degrees.\n",
    "\n",
    "* As the number of projections increases, the index range of singular values also increases. This is because increasing the number of projections means more information is available about the image, resulting in a more complete representation of the image in the Radon transform domain. This leads to a larger number of non-zero singular values, which increases the index range of the singular values.\n",
    "\n",
    "* The maximum value of singular value increases as the number of projections increases because increasing the number of projections means more information is available about the image, resulting in a more complete representation of the image in the Radon transform domain. This leads to a larger maximum singular value, which indicates that there is a stronger signal in the data.\n",
    "\n",
    "* The shape of the distribution of singular values among its index is similar as the number of projections increases because increasing the number of projections means more information is available about the image, resulting in a more complete representation of the image in the Radon transform domain. This leads to a more uniform distribution of singular values, which indicates that there is less noise in the data. As a result, the shape of the singular value distribution becomes more uniform and less sensitive to small changes in the number of projections, as long as the number of projections is sufficiently large. This is because the additional information provided by the extra projections helps to fill in gaps in the singular value distribution and reduce the effects of noise in the data.\n",
    "\n",
    "* Finally, the value of the singular value decreases along its index because the singular values represent the contribution of each singular vector to the image. The first few singular vectors represent the most significant contributions to the image, while the later singular vectors represent less significant contributions. As the number of projections increases, the first few singular vectors become more significant and contribute more to the image, while the later singular vectors become less significant and contribute less to the image. This leads to a decrease in the value of the singular values along its index.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Secondly, compute and plot the singular value spectrum for the Radon transform matrix of a given image size, for *different range of projection angles*. \n",
    "\n",
    "The method is similar to the previous function, but instead of changing the number of projections for the sinogram, this function changes the range of projection angles while keeping the number of projections fixed at $45$. The maximum angle range is varied by changing the *max_angles* parameter from $0-180$ degrees, and the resulting SVD spectrum is plotted against the maximum angle range.\n",
    "\n",
    "![solution](SVD_r_all.png)\n",
    "\n",
    "![solution](SVD_r.png)\n",
    "\n",
    "The graph of the SVD spectrum shows how the singular values of the Radon transform matrix vary with the range of angles used to generate the projection data. \n",
    "\n",
    "* The index range of singular values , as well as the maximum value of singular value, remain the same as the range of angles increases because the number of projection samples remains constant. The matrix $A$ is constructed with a fixed number of projection samples, which determines the number of rows in the matrix and the maximum index range of the singular values. The range of angles determines the number of columns in the matrix and the number of non-zero singular values, but it does not affect the index range of the singular values as well as the maximum singular value..\n",
    "\n",
    "* The distribution of singular values does not change proportionally as the range of angles increases because the limited-angle projection data contains less information about the image than the full-angle projection data. As a result, the limited-angle projection data may lead to a more incomplete and uneven representation of the image in the Radon transform domain, which can affect the shape and distribution of the singular values.\n",
    "\n",
    "In particular, the limited-angle projection data may lead to missing or distorted features in the image, which can result in gaps or peaks in the singular value distribution at certain indices. These gaps or peaks may be more prominent at intermediate indices, where the contribution of the missing or distorted features is most significant. The effect of limited-angle projection data on the singular value distribution can depend on the specific image and projection geometry, and may require careful regularisation or reconstruction techniques to mitigate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implement a matrix-free regularised least-squares solver for the Radon Transform.\n",
    "Now find a regularised solution to the inverse Radon Transform by solving\n",
    "$$(A^TA + αL)f_{∗} = A^Tg$$\n",
    "where $A$ is the Radon transform operator, $g$ is the measured sinogram, $f_*$ is the image to be reconstructed, $\\alpha$ is the regularisation parameter, and $L$ is the regularisation matrix. \n",
    "\n",
    "If order = $0$, the regularisation term is the identity matrix I. This corresponds to Tikhonov regularisation of the first order, which is given by:\n",
    "\n",
    "$$\\text{minimise} ||Ax - b||^2 + \\alpha * ||x||^2$$\n",
    "\n",
    "If order = $1$, the regularisation term is the Laplacian operator Lap(x), which is defined as the divergence of the gradient of x. This corresponds to Tikhonov regularisation of the second order, which is given by:\n",
    "\n",
    "$$\\text{minimise} ||Ax - b||^2 + \\alpha * ||\\text{Lap}(x)||^2$$\n",
    "\n",
    "\n",
    "(1) Firstly, build a function solving a regularised least squares problem using a matrix-free Krylov solver. \n",
    "\n",
    "I will define four functions here: `ATA_op`, `Ax`, and `b`, which are used to perform forward and backward propagation, compute the LHS and RHS of the regularised least squares problem, and compute the adjoint operator, respectively. And the `solve_reg_ls` function uses these three functions to set up a linear operator for *ATA* and solve the regularised least squares problem using the *GMRES* method. \n",
    "\n",
    "The `solve_reg_ls` function takes as input the true image *f*, the regularisation parameter *alpha*, the *order* of the regularisation order, the angle *theta* for the projection data, and the number of iterations *num_iters*.\n",
    "\n",
    "The `ATA_op` function performs the forward and backward propagation using the astra package, which is a software package for tomographic reconstruction. It takes as input the image *x*, the angle *theta*, and the regularisation parameter *alpha*, and returns the result of applying the operator *ATA* to *x*.\n",
    "\n",
    "The `Ax` function computes the LHS of the regularised least squares problem. It first performs the forward propagation using the astra package, and then adds noise to the sinogram before applying the regularisation operator to the result. It takes as input the image *x*, the angle *theta*, the regularisation parameter *alpha*, and the *order* of the regularisation order, and returns the result of applying the operator *Ax* to *x*.\n",
    "\n",
    "The `b` function computes the adjoint operator, which computes the RHS of the regularised least squares problem. It first performs the backward propagation using the astra package, and then returns the result. It takes as input the image *x*, the sinogram ID *y_id*, and the sinogram data *y*, and returns the result of applying the adjoint operator to y.\n",
    "\n",
    "The `solve_reg_ls` function sets up the linear operator for *ATA* using the LinearOperator class from the `scipy.sparse.linalg` package. It then computes the adjoint operator using the `b` function, and solves the linear system using the *GMRES* method. The function returns the reconstructed image *f_star*, the mean squared error *mse* between the reconstructed image and the filtered-backprojection image.\n",
    "\n",
    "**problems encountered and how they be solved:**\n",
    "* The `gmres` function requires a matrix and a vector as input, so I cannot use function `Ax` as input. To solve the problem, the `LinearOperator` function is used to create a linear operator that represents the matrix-vector product `Ax`, so that it can be inputted into `gmres`. Also, the vector input *ATg* should be flattened to match the shape of the linear operator, where the `ravel` function is used.\n",
    "\n",
    "* The size input of the LinearOperator function is not initially set up correctly to perform the Ax operation. Therefore, the size argument of the LinearOperator function is modified to be (M*N, M*N), where M and N are the dimensions of the true image f_true, so that the shape of the linear operator matches the shape of the input f_true. This ensures that the gmres function can correctly perform the matrix-vector multiplication.\n",
    "\n",
    "* The rertun of `gmres` function is NaN, with info > 0."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Then, find optimal regularisation parameter *alphas* for zero-order and first-order Tikhonov regularisation based on the sinogram data sinogram.\n",
    "\n",
    "The `find_alpha` function defined takes as input the *sinogram* data sinogram and returns the regularisation parameter *min_alpha0* for zero-order Tikhonov regularisation and *min_alpha1* for first-order Tikhonov regularisation.\n",
    "\n",
    "The function first defines a range of values for the regularisation parameter *alpha* using `np.linspace(0, 1, 100, endpoint=False)`, and then computes the mean squared error for each value of *alpha* using the `solve_reg_ls` function. It computes the *MSE* for both zero-order and first-order Tikhonov regularisation for each value of alpha.\n",
    "\n",
    "The function then finds the index of the minimum *MSE* value for both zero-order and first-order Tikhonov regularisation using `np.argmin`, and uses these indices to find the corresponding values of alpha (*min_alpha0* and *min_alpha1*).\n",
    "\n",
    "Also, the function plots the *MSE* values for different values of alpha for both zero-order and first-order Tikhonov regularisation for a visualisd illustration.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Finally, compare the performance of the regularised least-squares solver using matrix-free Krylov solver with different number of angles and limited angle range.\n",
    "\n",
    "The function takes as input the true image *f*, lists of *num_angles_list* and *max_angles_list* that specify the number of angles and the range of angles, respectively, and the optimal regularisation parameters (*min_alpha0*) and *min_alpha1* obtained from the `find_alpha` function.\n",
    "\n",
    "It computes the mean squared error (*MSE*) for both the zeroth and first order Tikhonov regularisation for different numbers of angles in *num_angles_list*, and plots the results. The MSE is computed by calling the `solve_reg_ls` function with the corresponding number of angles, optimal regularisation parameter, and regularisation order. The function then stores the MSE values for each order in *mse0_num_angles_list* and *mse1_num_angles_list*.\n",
    "\n",
    "Next, the function computes the *MSE* for both orders of regularisation for a limited range of angles specified in *max_angles_list* with a fixed number of *num_angles* equal to 45. The MSE values are stored in *mse0_max_angles* and *mse1_max_angles*.\n",
    "\n",
    "Finally, the function plots the *MSE* values obtained in the two steps above for both the zeroth and first order Tikhonov regularisation. The plots provide a comparison between the two regularisation orders and also between the different numbers and ranges of angles used.\n",
    "\n",
    "This comparison allows us to choose the best combination of regularisation order, number of angles and angle range that gives the lowest MSE for the reconstructed image."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a Haar wavelet denoiser.\n",
    "(1) I choose using the image of Shepp-Logan phantom and visualise the wavelet decomposition of the image, which decomposes the image into different scales and their corresponding frequency components.\n",
    "\n",
    "To find the decomposition, I apply the 2D Haar wavelet transform to the image using `pywt.wavedec2()` function. The output of this function is a tuple containing the approximation coefficients (cA) at the highest scale and the detail coefficients (cH, cV, cD) at lower scales.\n",
    "\n",
    "Then, I create a subplot of 7 rows and 3 columns and plots each of the detail coefficients in separate subplots along with their corresponding titles indicating the scale. The title of the subplot indicates which component of the wavelet transform (horizontal, vertical or diagonal) the subplot represents.\n",
    "\n",
    "![solution](W_d.png)\n",
    "\n",
    "Also, I plot the approximation coefficients (cA) at the highest scale in a separate plot with a title indicating the scale.\n",
    "\n",
    "![solution](W_a.png)\n",
    "\n",
    "As we have a 2D image of size (128, 128), after performing a 2D wavelet decomposition using the Haar wavelet, there are 7 scales of wavelet coefficients. For each scale, there are one set or three sets of coefficients representing the Approximation (cA), horizontal (cH), vertical (cV), and diagonal (cD) Detail, respectively.\n",
    "\n",
    "For the coarsest approximation coefficient (cA7), there is a single set with size 1 of coefficients representing the low-frequency approximation of the image.\n",
    "\n",
    "For the first scale (cH1, cV1, cD1), there are three sets of coefficients representing the horizontal, vertical, and diagonal details of the image, respectively. These sets of coefficients will be of size (64, 64).\n",
    "\n",
    "For the subsequent scales, there are three sets of coefficients of decreasing size. For example, for the second scale (cH2, cV2, cD2), we will get sets of coefficients of size (32, 32), and so on.\n",
    "\n",
    "The wavelet coefficients at the coarser scales (with higher scale index) capture the global features of the image and contain more low-frequency information, while the wavelet coefficients at finer scales (with lower scale index) capture the local features and details. As shown above, for images with more complex and detailed features, the wavelet coefficients at finer scales will be more significant and visible in the plot.\n",
    "\n",
    "In addition, at the finest scale, the horizontal, vertical, and diagonal detail coefficients represent the high-frequency components of the image, capturing details such as edges and texture. The corresponding plots for the horizontal, vertical, and diagonal detail coefficients look similar. However, there still be some differences due to the specific orientation of the features being captured by each direction. As we move to coarser scales, the detail coefficients capture lower-frequency components and the differences between the horizontal, vertical, and diagonal detail plots become more pronounced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
